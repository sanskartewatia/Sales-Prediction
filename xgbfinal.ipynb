{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from matplotlib import gridspec \n",
    "import random\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from math import sqrt\n",
    "train1 = pd.read_csv(\"train.csv\")\n",
    "test1 = pd.read_csv(\"test.csv\")\n",
    "top = np.percentile(train1.Purchase,99.5)\n",
    "sns.boxplot(x=train1[ (train1['Purchase']<top)].Purchase)\n",
    "train1 = train1[ (train1['Purchase']<top) ]\n",
    "test1['Purchase']=test1.index\n",
    "user_id_to_category_map = {}\n",
    "customer_purchase_power = train1.groupby(\"User_ID\")[\"Purchase\"].sum()\n",
    "#customer_purchase_power.median()\n",
    "\n",
    "values = customer_purchase_power.iteritems()\n",
    "for key, val in values:\n",
    "    if val <= 143662.0:\n",
    "        user_id_to_category_map[key] = 1\n",
    "    elif val <= 202156.0:\n",
    "        user_id_to_category_map[key] = 2\n",
    "    elif val <= 275408.0:\n",
    "        user_id_to_category_map[key] = 3\n",
    "    elif val <= 378451.0:\n",
    "        user_id_to_category_map[key] = 4\n",
    "    elif val <= 513874.0:\n",
    "        user_id_to_category_map[key] = 5\n",
    "    elif val <= 687241.0:\n",
    "        user_id_to_category_map[key] = 6\n",
    "    elif val <= 934097.0:\n",
    "        user_id_to_category_map[key] = 7\n",
    "    elif val <= 1332584.0:\n",
    "        user_id_to_category_map[key] = 8\n",
    "    elif val <= 2029891.0:\n",
    "        user_id_to_category_map[key] = 9\n",
    "    else:\n",
    "        user_id_to_category_map[key] = 10\n",
    "customer_purchase_power.median()\n",
    "def get_customer_category(user_id):\n",
    "    if user_id in user_id_to_category_map:\n",
    "        return user_id_to_category_map[user_id]\n",
    "    return 5\n",
    "train1[\"Purchasing_power\"] = list(map(lambda user_id: get_customer_category(user_id), train1[\"User_ID\"]))\n",
    "test1[\"Purchasing_power\"] = list(map(lambda user_id: get_customer_category(user_id), test1[\"User_ID\"]))\n",
    "#test1.head()\n",
    "train1 = train1.append(test1,sort=False,ignore_index=True)\n",
    "train1.fillna(-999,inplace=True)\n",
    "\n",
    "#OneHot Encoding of City Category - \n",
    "train1=pd.get_dummies(train1, columns=['City_Category'])\n",
    "train1['Product_Category_2'] = train1['Product_Category_2'].astype(int)\n",
    "train1['Product_Category_3'] = train1['Product_Category_3'].astype(int)\n",
    "train=train1[:547316]\n",
    "test=train1[547316:]\n",
    "test=test.drop(['Purchase'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-64a2cb926dd5>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"UID_Min\"] = train.groupby(['User_ID'])['Purchase'].transform('min')\n",
      "<ipython-input-8-64a2cb926dd5>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"UID_MaxP\"] = train.groupby(['User_ID'])['Purchase'].transform('max')\n",
      "<ipython-input-8-64a2cb926dd5>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"PID_MinP\"] = train.groupby(['Product_ID'])['Purchase'].transform('min')\n",
      "<ipython-input-8-64a2cb926dd5>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"PID_MaxP\"] = train.groupby(['Product_ID'])['Purchase'].transform('max')\n",
      "<ipython-input-8-64a2cb926dd5>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"User_ID_Count\"] = train.groupby(['User_ID'])['User_ID'].transform('count')\n",
      "<ipython-input-8-64a2cb926dd5>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Product_ID_Count\"] = train.groupby(['Product_ID'])['Product_ID'].transform('count')\n",
      "<ipython-input-8-64a2cb926dd5>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"UID_MeanP\"] = train.groupby(['User_ID'])['Purchase'].transform('mean')\n",
      "<ipython-input-8-64a2cb926dd5>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"PID_MeanP\"] = train.groupby(['Product_ID'])['Purchase'].transform('mean')\n",
      "<ipython-input-8-64a2cb926dd5>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Pc1_MeanP\"] = train.groupby(['Product_Category_1'])['Purchase'].transform('mean')\n",
      "<ipython-input-8-64a2cb926dd5>:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Pc1_MinP\"] = train.groupby(['Product_Category_1'])['Purchase'].transform('min')\n",
      "<ipython-input-8-64a2cb926dd5>:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Pc1_MaxP\"] = train.groupby(['Product_Category_1'])['Purchase'].transform('max')\n",
      "<ipython-input-8-64a2cb926dd5>:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Pc2_MeanP\"] = train.groupby(['Product_Category_2'])['Purchase'].transform('mean')\n",
      "<ipython-input-8-64a2cb926dd5>:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Pc2_MinP\"] = train.groupby(['Product_Category_2'])['Purchase'].transform('min')\n",
      "<ipython-input-8-64a2cb926dd5>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Pc2_MaxP\"] = train.groupby(['Product_Category_2'])['Purchase'].transform('max')\n",
      "<ipython-input-8-64a2cb926dd5>:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Pc3_MeanP\"] = train.groupby(['Product_Category_3'])['Purchase'].transform('mean')\n",
      "<ipython-input-8-64a2cb926dd5>:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Pc3_MinP\"] = train.groupby(['Product_Category_3'])['Purchase'].transform('min')\n",
      "<ipython-input-8-64a2cb926dd5>:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Pc3_MaxP\"] = train.groupby(['Product_Category_3'])['Purchase'].transform('max')\n",
      "<ipython-input-8-64a2cb926dd5>:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['UID_25Perc'] = train['User_ID'].apply(lambda x:userID_25p_dict.get(x,0))\n",
      "<ipython-input-8-64a2cb926dd5>:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['UID_50Perc'] = train['User_ID'].apply(lambda x:userID_50p_dict.get(x,0))\n",
      "<ipython-input-8-64a2cb926dd5>:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['UID_75Perc'] = train['User_ID'].apply(lambda x:userID_75p_dict.get(x,0))\n",
      "<ipython-input-8-64a2cb926dd5>:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['PID_25Perc'] = train['Product_ID'].apply(lambda x:productID_25p_dict.get(x,0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-64a2cb926dd5>:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['PID_50Perc'] = train['Product_ID'].apply(lambda x:productID_50p_dict.get(x,0))\n",
      "<ipython-input-8-64a2cb926dd5>:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['PID_75Perc'] = train['Product_ID'].apply(lambda x:productID_75p_dict.get(x,0))\n",
      "<ipython-input-8-64a2cb926dd5>:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['Pc1_25Perc'] = train['Product_Category_1'].apply(lambda x:pc1_25p_dict.get(x,0))\n",
      "<ipython-input-8-64a2cb926dd5>:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['Pc1_50Perc'] = train['Product_Category_1'].apply(lambda x:pc1_50p_dict.get(x,0))\n",
      "<ipython-input-8-64a2cb926dd5>:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['Pc1_75Perc'] = train['Product_Category_1'].apply(lambda x:pc1_75p_dict.get(x,0))\n",
      "<ipython-input-8-64a2cb926dd5>:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['Pc2_25Perc'] = train['Product_Category_2'].apply(lambda x:pc2_25p_dict.get(x,0))\n",
      "<ipython-input-8-64a2cb926dd5>:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['Pc2_50Perc'] = train['Product_Category_2'].apply(lambda x:pc2_50p_dict.get(x,0))\n",
      "<ipython-input-8-64a2cb926dd5>:115: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['Pc2_75Perc'] = train['Product_Category_2'].apply(lambda x:pc2_75p_dict.get(x,0))\n",
      "<ipython-input-8-64a2cb926dd5>:119: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['Pc3_25Perc'] = train['Product_Category_3'].apply(lambda x:pc3_25p_dict.get(x,0))\n",
      "<ipython-input-8-64a2cb926dd5>:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['Pc3_50Perc'] = train['Product_Category_3'].apply(lambda x:pc3_50p_dict.get(x,0))\n",
      "<ipython-input-8-64a2cb926dd5>:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['Pc3_75Perc'] = train['Product_Category_3'].apply(lambda x:pc3_75p_dict.get(x,0))\n",
      "<ipython-input-8-64a2cb926dd5>:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Occupation_Count\"] = train.groupby(['Occupation'])['Occupation'].transform('count')\n",
      "<ipython-input-8-64a2cb926dd5>:134: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Age_Count\"] = train.groupby(['Age'])['Age'].transform('count')\n",
      "<ipython-input-8-64a2cb926dd5>:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Product_Category_1_Count\"] = train.groupby(['Product_Category_1'])['Product_Category_1'].transform('count')\n",
      "<ipython-input-8-64a2cb926dd5>:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Product_Category_2_Count\"] = train.groupby(['Product_Category_2'])['Product_Category_2'].transform('count')\n",
      "<ipython-input-8-64a2cb926dd5>:146: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Product_Category_3_Count\"] = train.groupby(['Product_Category_3'])['Product_Category_3'].transform('count')\n"
     ]
    }
   ],
   "source": [
    "train[\"UID_Min\"] = train.groupby(['User_ID'])['Purchase'].transform('min')\n",
    "userID_min_dict = train.groupby(['User_ID'])['Purchase'].min().to_dict()\n",
    "test['UID_Min'] = test['User_ID'].apply(lambda x:userID_min_dict.get(x,0))\n",
    "\n",
    "train[\"UID_MaxP\"] = train.groupby(['User_ID'])['Purchase'].transform('max')\n",
    "userID_max_dict = train.groupby(['User_ID'])['Purchase'].max().to_dict()\n",
    "test['UID_MaxP'] = test['User_ID'].apply(lambda x:userID_max_dict.get(x,0))\n",
    "\n",
    "train[\"PID_MinP\"] = train.groupby(['Product_ID'])['Purchase'].transform('min')\n",
    "productID_min_dict = train.groupby(['Product_ID'])['Purchase'].min().to_dict()\n",
    "test['PID_MinP'] = test['Product_ID'].apply(lambda x:productID_min_dict.get(x,0))\n",
    "\n",
    "train[\"PID_MaxP\"] = train.groupby(['Product_ID'])['Purchase'].transform('max')\n",
    "productID_max_dict = train.groupby(['Product_ID'])['Purchase'].max().to_dict()\n",
    "test['PID_MaxP'] = test['Product_ID'].apply(lambda x:productID_max_dict.get(x,0))\n",
    "\n",
    "train[\"User_ID_Count\"] = train.groupby(['User_ID'])['User_ID'].transform('count')\n",
    "uID_count = train.groupby(['User_ID']).size().to_dict()\n",
    "test['User_ID_Count'] = test['User_ID'].apply(lambda x:uID_count.get(x,0))\n",
    "\n",
    "train[\"Product_ID_Count\"] = train.groupby(['Product_ID'])['Product_ID'].transform('count')\n",
    "pID_count = train.groupby(['Product_ID']).size().to_dict()\n",
    "test['Product_ID_Count'] = test['Product_ID'].apply(lambda x:pID_count.get(x,0))\n",
    "\n",
    "train[\"UID_MeanP\"] = train.groupby(['User_ID'])['Purchase'].transform('mean')\n",
    "userID_mean_dict = train.groupby(['User_ID'])['Purchase'].mean().to_dict()\n",
    "test['UID_MeanP'] = test['User_ID'].apply(lambda x:userID_mean_dict.get(x,0))\n",
    "\n",
    "train[\"PID_MeanP\"] = train.groupby(['Product_ID'])['Purchase'].transform('mean')\n",
    "productID_mean_dict = train.groupby(['Product_ID'])['Purchase'].mean().to_dict()\n",
    "test['PID_MeanP'] = test['Product_ID'].apply(lambda x:productID_mean_dict.get(x,0))\n",
    "\n",
    "train[\"Pc1_MeanP\"] = train.groupby(['Product_Category_1'])['Purchase'].transform('mean')\n",
    "pc1_mean_dict = train.groupby(['Product_Category_1'])['Purchase'].mean().to_dict()\n",
    "test['Pc1_MeanP'] = test['Product_Category_1'].apply(lambda x:pc1_mean_dict.get(x,0))\n",
    "\n",
    "train[\"Pc1_MinP\"] = train.groupby(['Product_Category_1'])['Purchase'].transform('min')\n",
    "pc1_min_dict = train.groupby(['Product_Category_1'])['Purchase'].min().to_dict()\n",
    "test['Pc1_MinP'] = test['Product_Category_1'].apply(lambda x:pc1_min_dict.get(x,0))\n",
    "\n",
    "train[\"Pc1_MaxP\"] = train.groupby(['Product_Category_1'])['Purchase'].transform('max')\n",
    "pc1_max_dict = train.groupby(['Product_Category_1'])['Purchase'].max().to_dict()\n",
    "test['Pc1_MaxP'] = test['Product_Category_1'].apply(lambda x:pc1_max_dict.get(x,0))\n",
    "\n",
    "train[\"Pc2_MeanP\"] = train.groupby(['Product_Category_2'])['Purchase'].transform('mean')\n",
    "pc2_mean_dict = train.groupby(['Product_Category_2'])['Purchase'].mean().to_dict()\n",
    "test['Pc2_MeanP'] = test['Product_Category_2'].apply(lambda x:pc2_mean_dict.get(x,0))\n",
    "\n",
    "train[\"Pc2_MinP\"] = train.groupby(['Product_Category_2'])['Purchase'].transform('min')\n",
    "pc2_min_dict = train.groupby(['Product_Category_2'])['Purchase'].min().to_dict()\n",
    "test['Pc2_MinP'] = test['Product_Category_2'].apply(lambda x:pc2_min_dict.get(x,0))\n",
    "\n",
    "train[\"Pc2_MaxP\"] = train.groupby(['Product_Category_2'])['Purchase'].transform('max')\n",
    "pc2_max_dict = train.groupby(['Product_Category_2'])['Purchase'].max().to_dict()\n",
    "test['Pc2_MaxP'] = test['Product_Category_2'].apply(lambda x:pc2_max_dict.get(x,0))\n",
    "\n",
    "train[\"Pc3_MeanP\"] = train.groupby(['Product_Category_3'])['Purchase'].transform('mean')\n",
    "pc3_mean_dict = train.groupby(['Product_Category_3'])['Purchase'].mean().to_dict()\n",
    "test['Pc3_MeanP'] = test['Product_Category_3'].apply(lambda x:pc3_mean_dict.get(x,0))\n",
    "\n",
    "train[\"Pc3_MinP\"] = train.groupby(['Product_Category_3'])['Purchase'].transform('min')\n",
    "pc3_min_dict = train.groupby(['Product_Category_3'])['Purchase'].min().to_dict()\n",
    "test['Pc3_MinP'] = test['Product_Category_3'].apply(lambda x:pc3_min_dict.get(x,0))\n",
    "\n",
    "train[\"Pc3_MaxP\"] = train.groupby(['Product_Category_3'])['Purchase'].transform('max')\n",
    "pc3_max_dict = train.groupby(['Product_Category_3'])['Purchase'].max().to_dict()\n",
    "test['Pc3_MaxP'] = test['Product_Category_3'].apply(lambda x:pc3_max_dict.get(x,0))\n",
    "\n",
    "userID_25p_dict = train.groupby(['User_ID'])['Purchase'].apply(lambda x:np.percentile(x,25)).to_dict()\n",
    "train['UID_25Perc'] = train['User_ID'].apply(lambda x:userID_25p_dict.get(x,0))\n",
    "test['UID_25Perc'] = test['User_ID'].apply(lambda x:userID_25p_dict.get(x,0))\n",
    "\n",
    "userID_50p_dict = train.groupby(['User_ID'])['Purchase'].apply(lambda x:np.percentile(x,50.)).to_dict()\n",
    "train['UID_50Perc'] = train['User_ID'].apply(lambda x:userID_50p_dict.get(x,0))\n",
    "test['UID_50Perc'] = test['User_ID'].apply(lambda x:userID_50p_dict.get(x,0))\n",
    "\n",
    "userID_75p_dict = train.groupby(['User_ID'])['Purchase'].apply(lambda x:np.percentile(x,75)).to_dict()\n",
    "train['UID_75Perc'] = train['User_ID'].apply(lambda x:userID_75p_dict.get(x,0))\n",
    "test['UID_75Perc'] = test['User_ID'].apply(lambda x:userID_75p_dict.get(x,0))\n",
    "\n",
    "productID_25p_dict = train.groupby(['Product_ID'])['Purchase'].apply(lambda x:np.percentile(x,25)).to_dict()\n",
    "train['PID_25Perc'] = train['Product_ID'].apply(lambda x:productID_25p_dict.get(x,0))\n",
    "test['PID_25Perc'] = test['Product_ID'].apply(lambda x:productID_25p_dict.get(x,0))\n",
    "\n",
    "productID_50p_dict = train.groupby(['Product_ID'])['Purchase'].apply(lambda x:np.percentile(x,50)).to_dict()\n",
    "train['PID_50Perc'] = train['Product_ID'].apply(lambda x:productID_50p_dict.get(x,0))\n",
    "test['PID_50Perc'] = test['Product_ID'].apply(lambda x:productID_50p_dict.get(x,0))\n",
    "\n",
    "productID_75p_dict = train.groupby(['Product_ID'])['Purchase'].apply(lambda x:np.percentile(x,75)).to_dict()\n",
    "train['PID_75Perc'] = train['Product_ID'].apply(lambda x:productID_75p_dict.get(x,0))\n",
    "test['PID_75Perc'] = test['Product_ID'].apply(lambda x:productID_75p_dict.get(x,0))\n",
    "\n",
    "pc1_25p_dict = train.groupby(['Product_Category_1'])['Purchase'].apply(lambda x:np.percentile(x,25)).to_dict()\n",
    "train['Pc1_25Perc'] = train['Product_Category_1'].apply(lambda x:pc1_25p_dict.get(x,0))\n",
    "test['Pc1_25Perc'] = test['Product_Category_1'].apply(lambda x:pc1_25p_dict.get(x,0))\n",
    "\n",
    "pc1_50p_dict = train.groupby(['Product_Category_1'])['Purchase'].apply(lambda x:np.percentile(x,50)).to_dict()\n",
    "train['Pc1_50Perc'] = train['Product_Category_1'].apply(lambda x:pc1_50p_dict.get(x,0))\n",
    "test['Pc1_50Perc'] = test['Product_Category_1'].apply(lambda x:pc1_50p_dict.get(x,0))\n",
    "\n",
    "pc1_75p_dict = train.groupby(['Product_Category_1'])['Purchase'].apply(lambda x:np.percentile(x,75)).to_dict()\n",
    "train['Pc1_75Perc'] = train['Product_Category_1'].apply(lambda x:pc1_75p_dict.get(x,0))\n",
    "test['Pc1_75Perc'] = test['Product_Category_1'].apply(lambda x:pc1_75p_dict.get(x,0))\n",
    "\n",
    "\n",
    "pc2_25p_dict = train.groupby(['Product_Category_2'])['Purchase'].apply(lambda x:np.percentile(x,25)).to_dict()\n",
    "train['Pc2_25Perc'] = train['Product_Category_2'].apply(lambda x:pc2_25p_dict.get(x,0))\n",
    "test['Pc2_25Perc'] = test['Product_Category_2'].apply(lambda x:pc2_25p_dict.get(x,0))\n",
    "\n",
    "pc2_50p_dict = train.groupby(['Product_Category_2'])['Purchase'].apply(lambda x:np.percentile(x,50)).to_dict()\n",
    "train['Pc2_50Perc'] = train['Product_Category_2'].apply(lambda x:pc2_50p_dict.get(x,0))\n",
    "test['Pc2_50Perc'] = test['Product_Category_2'].apply(lambda x:pc2_50p_dict.get(x,0))\n",
    "\n",
    "pc2_75p_dict = train.groupby(['Product_Category_2'])['Purchase'].apply(lambda x:np.percentile(x,75)).to_dict()\n",
    "train['Pc2_75Perc'] = train['Product_Category_2'].apply(lambda x:pc2_75p_dict.get(x,0))\n",
    "test['Pc2_75Perc'] = test['Product_Category_2'].apply(lambda x:pc2_75p_dict.get(x,0))\n",
    "\n",
    "pc3_25p_dict = train.groupby(['Product_Category_3'])['Purchase'].apply(lambda x:np.percentile(x,25)).to_dict()\n",
    "train['Pc3_25Perc'] = train['Product_Category_3'].apply(lambda x:pc3_25p_dict.get(x,0))\n",
    "test['Pc3_25Perc'] = test['Product_Category_3'].apply(lambda x:pc3_25p_dict.get(x,0))\n",
    "\n",
    "pc3_50p_dict = train.groupby(['Product_Category_3'])['Purchase'].apply(lambda x:np.percentile(x,50)).to_dict()\n",
    "train['Pc3_50Perc'] = train['Product_Category_3'].apply(lambda x:pc3_50p_dict.get(x,0))\n",
    "test['Pc3_50Perc'] = test['Product_Category_3'].apply(lambda x:pc3_50p_dict.get(x,0))\n",
    "\n",
    "pc3_75p_dict = train.groupby(['Product_Category_3'])['Purchase'].apply(lambda x:np.percentile(x,75)).to_dict()\n",
    "train['Pc3_75Perc'] = train['Product_Category_3'].apply(lambda x:pc3_75p_dict.get(x,0))\n",
    "test['Pc3_75Perc'] = test['Product_Category_3'].apply(lambda x:pc3_75p_dict.get(x,0))\n",
    "\n",
    "train[\"Occupation_Count\"] = train.groupby(['Occupation'])['Occupation'].transform('count')\n",
    "occupation_count_dict = train.groupby(['Occupation']).size().to_dict()\n",
    "test['Occupation_Count'] = test['Occupation'].apply(lambda x:occupation_count_dict.get(x,0))\n",
    "\n",
    "train[\"Age_Count\"] = train.groupby(['Age'])['Age'].transform('count')\n",
    "age_count_dict = train.groupby(['Age']).size().to_dict()\n",
    "test['Age_Count'] = test['Age'].apply(lambda x:age_count_dict.get(x,0))\n",
    "\n",
    "train[\"Product_Category_1_Count\"] = train.groupby(['Product_Category_1'])['Product_Category_1'].transform('count')\n",
    "pc1_count_dict = train.groupby(['Product_Category_1']).size().to_dict()\n",
    "test['Product_Category_1_Count'] = test['Product_Category_1'].apply(lambda x:pc1_count_dict.get(x,0))\n",
    "\n",
    "train[\"Product_Category_2_Count\"] = train.groupby(['Product_Category_2'])['Product_Category_2'].transform('count')\n",
    "pc2_count_dict = train.groupby(['Product_Category_2']).size().to_dict()\n",
    "test['Product_Category_2_Count'] = test['Product_Category_2'].apply(lambda x:pc2_count_dict.get(x,0))\n",
    "\n",
    "train[\"Product_Category_3_Count\"] = train.groupby(['Product_Category_3'])['Product_Category_3'].transform('count')\n",
    "pc3_count_dict = train.groupby(['Product_Category_3']).size().to_dict()\n",
    "test['Product_Category_3_Count'] = test['Product_Category_3'].apply(lambda x:pc3_count_dict.get(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-4d8801a44f54>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Gender\"] = train[\"Gender\"].apply(lambda x: gender_dict[x])\n",
      "<ipython-input-9-4d8801a44f54>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Age\"] = train[\"Age\"].apply(lambda x: age_dict[x])\n",
      "<ipython-input-9-4d8801a44f54>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"Stay_In_Current_City_Years\"] = train[\"Stay_In_Current_City_Years\"].apply(lambda x: stay_dict[x])\n",
      "<ipython-input-9-4d8801a44f54>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[var] = lb.transform(train[var].astype('str'))\n",
      "C:\\Users\\tsans\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "User_ID                         int32\n",
       "Product_ID                      int32\n",
       "Gender                          int64\n",
       "Age                             int64\n",
       "Occupation                      int64\n",
       "Stay_In_Current_City_Years      int64\n",
       "Marital_Status                  int64\n",
       "Product_Category_1              int64\n",
       "Product_Category_2              int32\n",
       "Product_Category_3              int32\n",
       "Purchasing_power                int64\n",
       "City_Category_A                 uint8\n",
       "City_Category_B                 uint8\n",
       "City_Category_C                 uint8\n",
       "UID_Min                         int64\n",
       "UID_MaxP                        int64\n",
       "PID_MinP                        int64\n",
       "PID_MaxP                        int64\n",
       "User_ID_Count                   int64\n",
       "Product_ID_Count                int64\n",
       "UID_MeanP                     float64\n",
       "PID_MeanP                     float64\n",
       "Pc1_MeanP                     float64\n",
       "Pc1_MinP                        int64\n",
       "Pc1_MaxP                        int64\n",
       "Pc2_MeanP                     float64\n",
       "Pc2_MinP                        int64\n",
       "Pc2_MaxP                        int64\n",
       "Pc3_MeanP                     float64\n",
       "Pc3_MinP                        int64\n",
       "Pc3_MaxP                        int64\n",
       "UID_25Perc                    float64\n",
       "UID_50Perc                    float64\n",
       "UID_75Perc                    float64\n",
       "PID_25Perc                    float64\n",
       "PID_50Perc                    float64\n",
       "PID_75Perc                    float64\n",
       "Pc1_25Perc                    float64\n",
       "Pc1_50Perc                    float64\n",
       "Pc1_75Perc                    float64\n",
       "Pc2_25Perc                    float64\n",
       "Pc2_50Perc                    float64\n",
       "Pc2_75Perc                    float64\n",
       "Pc3_25Perc                    float64\n",
       "Pc3_50Perc                    float64\n",
       "Pc3_75Perc                    float64\n",
       "Occupation_Count                int64\n",
       "Age_Count                       int64\n",
       "Product_Category_1_Count        int64\n",
       "Product_Category_2_Count        int64\n",
       "Product_Category_3_Count        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_dict = {'F':0, 'M':1}\n",
    "age_dict = {'0-17':0, '18-25':1, '26-35':2, '36-45':3, '46-50':4, '51-55':5, '55+':6}\n",
    "stay_dict = {'0':0, '1':1, '2':2, '3':3, '4+':4}\n",
    "\n",
    "train[\"Gender\"] = train[\"Gender\"].apply(lambda x: gender_dict[x])\n",
    "test[\"Gender\"] = test[\"Gender\"].apply(lambda x: gender_dict[x])\n",
    "\n",
    "train[\"Age\"] = train[\"Age\"].apply(lambda x: age_dict[x])\n",
    "test[\"Age\"] = test[\"Age\"].apply(lambda x: age_dict[x])\n",
    "\n",
    "train[\"Stay_In_Current_City_Years\"] = train[\"Stay_In_Current_City_Years\"].apply(lambda x: stay_dict[x])\n",
    "test[\"Stay_In_Current_City_Years\"] = test[\"Stay_In_Current_City_Years\"].apply(lambda x: stay_dict[x])\n",
    "\n",
    "xg1 = pd.DataFrame()\n",
    "xg1['User_ID'] = test['User_ID']\n",
    "xg1['Product_ID'] = test['Product_ID']\n",
    "cat_col=[\"User_ID\", \"Product_ID\"]\n",
    "for var in cat_col:\n",
    "    lb = preprocessing.LabelEncoder()\n",
    "    full_var_data = pd.concat((train[var], test[var]), axis=0).astype('str')\n",
    "    lb.fit(full_var_data)\n",
    "    train[var] = lb.transform(train[var].astype('str'))\n",
    "    test[var] = lb.transform(test[var].astype('str'))\n",
    "train_y = train[\"Purchase\"]\n",
    "train.drop([\"Purchase\"], axis=1, inplace=True)\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, train_y, test_size=0.05, random_state=42)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 88.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:03:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "0.7665551873834866\n",
      "{'colsample_bytree': 0.7, 'learning_rate': 0.03, 'max_depth': 10, 'min_child_weight': 10, 'n_estimators': 750, 'nthread': -1, 'objective': 'reg:linear', 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "import datetime\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "xgb1 = XGBRegressor()\n",
    "parameters = {'nthread':[-1], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [0.01, 0.03],\n",
    "              'max_depth': [10],\n",
    "              'min_child_weight': [5, 10],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500, 750]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 5,\n",
    "                        n_jobs = -1,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(train,\n",
    "         train_y)\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "params = {}\n",
    "params[\"eta\"] = 0.03\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.8\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"max_depth\"] = 10\n",
    "params[\"seed\"] = 0\n",
    "params[\"n_estimators\"]=750\n",
    "num_rounds = 1500\n",
    "plst = list(params.items())\n",
    "xgtrain = xgb.DMatrix(train, label=train_y)\n",
    "model = xgb.train(plst, xgtrain,num_rounds)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "xgtest = xgb.DMatrix(test)\n",
    "pred=model.predict(xgtest)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg1['Purchase'] = pred\n",
    "#sum(n < 30 for n in xg1[\"Purchase\"].values.flatten())\n",
    "xg1[xg1[\"Purchase\"] < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg1.to_csv('xgbfinal.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importance (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PID_MeanP</td>\n",
       "      <td>46.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PID_50Perc</td>\n",
       "      <td>10.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PID_75Perc</td>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PID_25Perc</td>\n",
       "      <td>5.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UID_75Perc</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UID_MeanP</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UID_25Perc</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UID_50Perc</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pc1_MaxP</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pc1_50Perc</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PID_MaxP</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pc1_MinP</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gender</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pc1_25Perc</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pc1_75Perc</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pc1_MeanP</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>UID_MaxP</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>User_ID_Count</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Purchasing_power</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Product_Category_3_Count</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pc3_50Perc</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pc3_MinP</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>City_Category_A</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pc3_MaxP</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Product_Category_1</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>User_ID</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Age_Count</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Pc3_25Perc</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>City_Category_C</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Pc3_75Perc</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Product_Category_2_Count</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pc2_MinP</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Occupation_Count</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Pc2_50Perc</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Product_Category_3</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Pc2_75Perc</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pc3_MeanP</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Occupation</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UID_Min</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Product_Category_1_Count</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PID_MinP</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Pc2_25Perc</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Stay_In_Current_City_Years</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Pc2_MeanP</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Product_ID_Count</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Pc2_MaxP</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Product_Category_2</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Product_ID</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>City_Category_B</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Marital_Status</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Features  Importance (%)\n",
       "0                    PID_MeanP           46.78\n",
       "1                   PID_50Perc           10.87\n",
       "2                   PID_75Perc            9.30\n",
       "3                   PID_25Perc            5.16\n",
       "4                   UID_75Perc            1.26\n",
       "5                    UID_MeanP            1.22\n",
       "6                   UID_25Perc            1.01\n",
       "7                   UID_50Perc            0.97\n",
       "8                     Pc1_MaxP            0.90\n",
       "9                   Pc1_50Perc            0.78\n",
       "10                    PID_MaxP            0.74\n",
       "11                    Pc1_MinP            0.74\n",
       "12                      Gender            0.71\n",
       "13                  Pc1_25Perc            0.69\n",
       "14                  Pc1_75Perc            0.69\n",
       "15                   Pc1_MeanP            0.66\n",
       "16                    UID_MaxP            0.65\n",
       "17               User_ID_Count            0.63\n",
       "18            Purchasing_power            0.56\n",
       "19                         Age            0.54\n",
       "20    Product_Category_3_Count            0.54\n",
       "21                  Pc3_50Perc            0.54\n",
       "22                    Pc3_MinP            0.53\n",
       "23             City_Category_A            0.53\n",
       "24                    Pc3_MaxP            0.52\n",
       "25          Product_Category_1            0.52\n",
       "26                     User_ID            0.52\n",
       "27                   Age_Count            0.51\n",
       "28                  Pc3_25Perc            0.51\n",
       "29             City_Category_C            0.51\n",
       "30                  Pc3_75Perc            0.51\n",
       "31    Product_Category_2_Count            0.50\n",
       "32                    Pc2_MinP            0.50\n",
       "33            Occupation_Count            0.50\n",
       "34                  Pc2_50Perc            0.49\n",
       "35          Product_Category_3            0.49\n",
       "36                  Pc2_75Perc            0.49\n",
       "37                   Pc3_MeanP            0.49\n",
       "38                  Occupation            0.48\n",
       "39                     UID_Min            0.48\n",
       "40    Product_Category_1_Count            0.47\n",
       "41                    PID_MinP            0.47\n",
       "42                  Pc2_25Perc            0.47\n",
       "43  Stay_In_Current_City_Years            0.46\n",
       "44                   Pc2_MeanP            0.46\n",
       "45            Product_ID_Count            0.46\n",
       "46                    Pc2_MaxP            0.46\n",
       "47          Product_Category_2            0.44\n",
       "48                  Product_ID            0.44\n",
       "49             City_Category_B            0.43\n",
       "50              Marital_Status            0.41"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "feature_important = model.get_score(importance_type='gain')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())\n",
    "total = sum(values)\n",
    "new = [value * 100. / total for value in values]\n",
    "new = np.round(new,2)\n",
    "\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['Features'] = keys\n",
    "feature_importances['Importance (%)'] = new\n",
    "feature_importances = feature_importances.sort_values(['Importance (%)'],ascending=False).reset_index(drop=True)\n",
    "feature_importances\n",
    "#feature_importances.style.set_properties(**{'font-size':'10pt'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
